{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Packages and Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import mysql.connector as mysql\n",
    "import time\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "size=100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = np.load(f'data/mnist1_{size}.npy').astype(np.float32)\n",
    "q = np.load(f'data/mnist2_{size}.npy').astype(np.float32)\n",
    "assert p.shape[0] == q.shape[0]\n",
    "assert p.shape[1] ==784\n",
    "assert q.shape[1] == 784\n",
    "\n",
    "n = p.shape[0]\n",
    "pixels = p.shape[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Methods for Computing Distances\n",
    "\n",
    "The methods shown below demonstrate a range of approaches for computing the pairwise distances between MNIST images in two data sets.  The available data sets contain either 10, 100, 1000, 10000, or 60000 images, each of which is constituted by 784 pixels encoded as floating-point values.  A data set with <code>n</code> images constitutes a <code>numpy</code> that is $n \\times 784$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Base Python: Nested <code>for</code> Loops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exec. time: 27.43082594871521 for 100x100\n",
      "[10.553867 10.057241  8.833829  9.928223  8.737533]\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "result = np.zeros((n,n)).astype(np.float32)\n",
    "for i in range(n):\n",
    "    for j in range(n):\n",
    "        sum_sq = 0.0\n",
    "        for k in range(pixels):\n",
    "            sum_sq += (q[i][k] - p[j][k])**2\n",
    "        result[i][j] = math.sqrt(sum_sq)\n",
    "\n",
    "print('Exec. time: %s for %sx%s' % (str(float(time.time() - start)), str(n), str(n)))\n",
    "print(result[0,:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Algebra Approach Using Matrix-Vector Math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exec. time: 0.08700108528137207 for 100x100\n",
      "[10.553867 10.057241  8.833829  9.928222  8.737532]\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "result = np.zeros((n,n)).astype(np.float32)\n",
    "for i in range(n):\n",
    "    for j in range(n):\n",
    "        result[i][j] = np.sqrt(q[i]@q[i]-2*p[j]@q[i]+p[j]@p[j])\n",
    "\n",
    "print('Exec. time: %s for %sx%s' % (str(float(time.time() - start)), str(n), str(n)))\n",
    "print(result[0,:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Element-wise (Vectorized) Math with <code>numpy</code> and Nested <code>for</code> Loops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exec. time: 0.06618976593017578 for 100x100\n",
      "[10.553867 10.057242  8.83383   9.928222  8.737532]\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "result = np.zeros((n,n)).astype(np.float32)\n",
    "for i in range(n):\n",
    "    for j in range(n):\n",
    "        result[i][j] = np.sqrt(((q[i]-p[j])**2).sum())\n",
    "\n",
    "print('Exec. time: %s for %sx%s' % (str(float(time.time() - start)), str(n), str(n)))\n",
    "print(result[0,:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <code>numpy np.newaxis()</code> to Avoid Loops via Broadcasting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exec. time: 0.02643442153930664 for 100x100\n",
      "[10.553867 10.057242  8.83383   9.928222  8.737532]\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "#result = np.sqrt((q-p)@(q-p).T)\n",
    "result = np.sqrt(((q[:, np.newaxis, :] - p)*(q[:, np.newaxis, :] - p)).sum(axis=2))\n",
    "\n",
    "print('Exec. time: %s for %sx%s' % (str(float(time.time() - start)), str(n), str(n)))\n",
    "print(result[0,:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using the <code>numpy</code> Method <code> np.linalg.norm()</code>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exec. time: 2.137239694595337 for 1000x1000\n",
      "[10.553867 10.057242  8.83383   9.928222  8.737532]\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "#result = np.sqrt((q-p)@(q-p).T)\n",
    "result = np.linalg.norm(q[:, np.newaxis, :] - p, axis=2)\n",
    "\n",
    "print('Exec. time: %s for %sx%s' % (str(float(time.time() - start)), str(n), str(n)))\n",
    "print(result[0,:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using the <code>scipy</code> Method <code> scipy.spatial.distance.cdist()</code>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exec. time: 0.5108568668365479 for 1000x1000\n",
      "[10.5538673  10.05724184  8.83382935  9.92822226  8.73753215]\n"
     ]
    }
   ],
   "source": [
    "from scipy.spatial.distance import cdist\n",
    "start = time.time()\n",
    "result = cdist(q,p)\n",
    "print('Exec. time: %s for %sx%s' % (str(float(time.time() - start)), str(n), str(n)))\n",
    "print(result[0,:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to <code>np.einsum()</code>\n",
    "\n",
    "This <code>numpy</code> quickly multiplies arrays while summing across specified axis.  It requires as input a string in \"Einstein Notation\" that determines how the arrays will be multipled (e.g., vector-matrix multiplcation versus elementwise (vectorized) multiplication)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Einstein Notation\n",
    "\n",
    "Einstein notation give a roadmap for how <code>numpy</code> arrays and vectors are to be multiplied using single-characters each of which corresponds to a dimension (think rows and columns) of a <code>numpy</code> that is to be multiplied.  Further, when <code>np.einsum()</code> is used sums are often computed on the array that results from the specified multiplication operation.  \n",
    "\n",
    "A typical example of Einstein notation is this:\n",
    "\n",
    "``` python\n",
    "'ij,jk->ik'\n",
    "```\n",
    "\n",
    "where\n",
    "\n",
    " - <code>i</code> represents the rows of the first input and <code>j</code> its column indices\n",
    " - <code>j</code> represents the rows of the second input and <code>k</code> its column indices\n",
    " - The symbol <code>-></code> separates inputs (on the left) from the output (on the right)\n",
    " - <code>ik</code> indicates that the output array has rows corresponding with the first input and columns corresponding with the second input.\n",
    "\n",
    "As is demonstrated below, these two characteristics of the letters/indices used are important:\n",
    "\n",
    "- The order of the indices in the Einstein notation\n",
    "- Which indices used to represent the original inputs are either included in the specification fo the output, or not\n",
    "\n",
    "The following page documents Einstien notation and gives examples: [link_fort_Einstein_Notation](https://numpy.org/doc/stable/reference/generated/numpy.einsum.html)\n",
    "\n",
    "first, we create two small arrays for demonstration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[6 2 4]\n",
      " [8 6 9]\n",
      " [0 5 5]] \n",
      "\n",
      " [[4 2 8]\n",
      " [2 6 0]\n",
      " [6 9 5]]\n"
     ]
    }
   ],
   "source": [
    "mat1 = np.random.randint(0,10,(3,3))\n",
    "mat2 = np.random.randint(0,10,(3,3))\n",
    "print(mat1,'\\n\\n',mat2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This first example does not use <code>np.einsum()</code> but it, rather, shows three calculations that we might make with the two arrays, respectively, \n",
    "\n",
    "- The dot product of the two arrays \n",
    "- Elementwise multiplication of the two arrays\n",
    "- The dot product of the two arays, subsequently summed along axis 0\n",
    "- The dot product of the two arays, subsequently summed along axis 1\n",
    "- The dot product of the two arays, subsequently summed along both axes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dot Product\n",
      " [[ 52  60  68]\n",
      " [ 98 133 109]\n",
      " [ 40  75  25]]\n",
      "\n",
      "Dot Product, summed on axis=0\n",
      " [190 268 202]\n",
      "\n",
      "Dot Product, summed on axis=1\n",
      " [180 340 140]\n",
      "\n",
      "Dot Product, summed on both axes\n",
      " 660\n",
      "\n",
      "Elementwise Product\n",
      " [[24  4 32]\n",
      " [16 36  0]\n",
      " [ 0 45 25]]\n",
      "\n",
      "Elementwise Product, summed on axis=0\n",
      " [40 85 57]\n",
      "\n",
      "Elementwise Product, summed on axis=1\n",
      " [60 52 70]\n",
      "\n",
      "Elementwise Product, summed on both axes\n",
      " 182\n"
     ]
    }
   ],
   "source": [
    "''' Dot products/matrix-vector math mode '''\n",
    "print('Dot Product\\n',mat1@mat2)\n",
    "print('\\nDot Product, summed on axis=0\\n',(mat1@mat2).sum(axis=0))\n",
    "print('\\nDot Product, summed on axis=1\\n',(mat1@mat2).sum(axis=1))\n",
    "print('\\nDot Product, summed on both axes\\n',(mat1@mat2).sum())\n",
    "\n",
    "''' Elementwise/vectorized computations '''\n",
    "print('\\nElementwise Product\\n', mat1*mat2)\n",
    "print('\\nElementwise Product, summed on axis=0\\n',(mat1*mat2).sum(axis=0))\n",
    "print('\\nElementwise Product, summed on axis=1\\n',(mat1*mat2).sum(axis=1))\n",
    "print('\\nElementwise Product, summed on both axes\\n',(mat1*mat2).sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This first example of <code>np.einsum()</code> uses Einstein notation that denotes the dot product:\n",
    "\n",
    "``` python\n",
    "'ij,jk->ik'\n",
    "```\n",
    "\n",
    "Notably, the <code>j</code> relates to the column indices of the first input as well as the row indices of the second input, which indicates that the elements in the rows of the first input are to be multiplied by the columns in the second input, as is done with the dot product.  The <code>ik</code> indicates that the result has two dimensions with the row indices relating to the first input and the column indices relating to the second input, again, as is the case with the dot product.\n",
    "\n",
    "Note that the absence of an output specification results in a dot product with the input specifications as shown here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 52  60  68]\n",
      " [ 98 133 109]\n",
      " [ 40  75  25]]\n"
     ]
    }
   ],
   "source": [
    "result = np.einsum('ij,jk->ik', mat1, mat2)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 52  60  68]\n",
      " [ 98 133 109]\n",
      " [ 40  75  25]]\n"
     ]
    }
   ],
   "source": [
    "result = np.einsum('ij,jk', mat1, mat2)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It was claimed earlier that the order of the indices mattered, as is demonstrated below.  reversing the <code>i</code> and <code>k</code> in the output specification causes the output to be the transpose of the prior respective result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 52  98  40]\n",
      " [ 60 133  75]\n",
      " [ 68 109  25]]\n"
     ]
    }
   ],
   "source": [
    "result = np.einsum('ij,jk->ki', mat1, mat2)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The two computations below sum along either of the axes depending whether the output is speciified to be related with the <code>i</code> or <code>j</code> indices.  <code>i</code> refers to the rows of the first input, and so the sum is along the columns.  Conversely, specifying the output with <code>k</code> sums along axis 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[190 268 202]\n"
     ]
    }
   ],
   "source": [
    "result = np.einsum('ij,jk->k', mat1, mat2)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[180 340 140]\n"
     ]
    }
   ],
   "source": [
    "result = np.einsum('ij,jk->i', mat1, mat2)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Summing along both axes with dot product being indicated with the inputs requires the <code>-></code> symbol with no output specification. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "660\n"
     ]
    }
   ],
   "source": [
    "result = np.einsum('ij,jk->', mat1, mat2)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Elementwise multiplication, without summing, is down by listing the indices characters in the same order, with both indices characters also listed in the output specification.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[24  4 32]\n",
      " [16 36  0]\n",
      " [ 0 45 25]]\n"
     ]
    }
   ],
   "source": [
    "result = np.einsum('ij,ij->ij', mat1, mat2)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similarly to a previous example, one can generate the transpose result by switching the characters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[24 16  0]\n",
      " [ 4 36 45]\n",
      " [32  0 25]]\n"
     ]
    }
   ],
   "source": [
    "result = np.einsum('ij,ij->ji', mat1, mat2)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Summing along axes is done as shown before with dot products.  Listing <code>i</code> will cause the summation to occur acoross the unlisted indices (<code>j</code>), that is across the columns as in <code>axis=1</code>.  Conversely listing <code>j</code> in the output specification causes summation as in <code>axis=1</code>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[60 52 70]\n"
     ]
    }
   ],
   "source": [
    "result = np.einsum('ij,ij->i', mat1, mat2)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[40 85 57]\n"
     ]
    }
   ],
   "source": [
    "result = np.einsum('ij,ij->j', mat1, mat2)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Summing along all axes in accomplishing by omitting an output specification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "182\n"
     ]
    }
   ],
   "source": [
    "result = np.einsum('ij,ij', mat1, mat2)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Einstein notation is just as applicable with vectors (single dimension arrays) but, of course, only one index character can be used with them since they have but one dimension."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "vec_one = np.ones(mat1.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12. 23. 10.]\n"
     ]
    }
   ],
   "source": [
    "print(np.einsum('ij,j',mat1,vec_one))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14. 13. 18.]\n"
     ]
    }
   ],
   "source": [
    "print(np.einsum('ij,i',mat1,vec_one))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14. 13. 18.]\n"
     ]
    }
   ],
   "source": [
    "print(np.einsum('i,ij',vec_one,mat1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14. 13. 18.]\n"
     ]
    }
   ],
   "source": [
    "print(np.einsum('i,ij->j',vec_one,mat1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14. 13. 18.]\n"
     ]
    }
   ],
   "source": [
    "print(np.einsum('ij,i->j',mat1,vec_one))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45.0\n"
     ]
    }
   ],
   "source": [
    "print(np.einsum('ij,i->',mat1,vec_one))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[6. 2. 4.]\n",
      " [8. 6. 9.]\n",
      " [0. 5. 5.]]\n"
     ]
    }
   ],
   "source": [
    "print(np.einsum('ij,i->ij',mat1,vec_one))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Computing Distances with <code>np.einsum()</code>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exec. time: 0.0009982585906982422 for 100x100\n",
      "[10.553866 10.057241  8.833829  9.928222  8.737532]\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "#result = np.sqrt(np.diag(q@q.T) -2*q@p.T + np.diag(p@p.T).reshape(-1,1))\n",
    "result_ein = np.sqrt(np.einsum('ij,ij->i',q,q)[:,np.newaxis] - 2*q@p.T + np.einsum('ij,ij->i',p,p))\n",
    "\n",
    "print('Exec. time: %s for %sx%s' % (str(float(time.time() - start)), str(n), str(n)))\n",
    "print(result_ein[0,:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 9.5367432e-07,  0.0000000e+00,  0.0000000e+00, ...,\n",
       "         0.0000000e+00,  0.0000000e+00,  0.0000000e+00],\n",
       "       [ 9.5367432e-07,  9.5367432e-07,  0.0000000e+00, ...,\n",
       "        -9.5367432e-07,  0.0000000e+00,  0.0000000e+00],\n",
       "       [ 9.5367432e-07,  9.5367432e-07,  0.0000000e+00, ...,\n",
       "         0.0000000e+00,  9.5367432e-07,  0.0000000e+00],\n",
       "       ...,\n",
       "       [ 1.9073486e-06,  9.5367432e-07,  9.5367432e-07, ...,\n",
       "         9.5367432e-07,  9.5367432e-07,  9.5367432e-07],\n",
       "       [ 9.5367432e-07,  9.5367432e-07,  0.0000000e+00, ...,\n",
       "         0.0000000e+00,  0.0000000e+00,  0.0000000e+00],\n",
       "       [ 0.0000000e+00,  0.0000000e+00,  0.0000000e+00, ...,\n",
       "         0.0000000e+00,  0.0000000e+00,  0.0000000e+00]], dtype=float32)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(result - result_ein)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
